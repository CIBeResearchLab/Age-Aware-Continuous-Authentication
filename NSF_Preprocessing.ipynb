{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NSF_Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#NSF Data Preprocessing below:\n",
        "Instructions:\n",
        "\n",
        "1.   If it is the first time running the code in a given session, be sure to press \"Ctrl+F9\" or Runtime->Run all or run each cell individually as well as ensuring that it is properly connected to the participant data folder in Drive. Running each cell should incur the request to mount the Drive automatically as the path points to it, however, if that is not the case, click the folder icon in the left-hand sidebar and select the \"Mount Drive\" icon with the Google Drive logo.\n",
        "2.   Be sure to input the desired participant prior to selecting Run all to avoid possible duplicates.\n",
        "3.   Ensure that all installs and imports are up to date as new code is added.\n",
        "4.   Most importantly, keep the participant data folder up to date with the most current participant data.\n",
        "5.   The first execution should take about a minute or so, however, if it is still running seemingly slow: Runtime->Change runtime type->Hardware accelerator->GPU->Save.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "56jQFLbMFr7T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Required Installs: \n",
        "\n",
        "1.   python-docx: allows data handling from a .docx file\n",
        "2.   pathlib: allows for path handling\n"
      ],
      "metadata": {
        "id": "71jIo_XbIKf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EThkP2JOf1E",
        "outputId": "c9d9d4d9-1347-4b89-d3f7-dd97aa40f202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 13.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from python-docx) (4.2.6)\n",
            "Building wheels for collected packages: python-docx\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184507 sha256=f2e236f358b099dd5a4671d51cb636bb01f9557b9588d5234bef94ae6365fcdd\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/6f/b9/d798122a8b55b74ad30b5f52b01482169b445fbb84a11797a6\n",
            "Successfully built python-docx\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-0.8.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pathlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibRSxGAkkZNM",
        "outputId": "b534f79a-e6cd-4025-805f-f650f01c89ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.7/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Required Imports"
      ],
      "metadata": {
        "id": "6RMgHs7o8kwd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNM-y7qQFphg"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import glob\n",
        "import json\n",
        "import os\n",
        "import docx\n",
        "import zipfile\n",
        "import xml\n",
        "import io"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mounts the Google Drive"
      ],
      "metadata": {
        "id": "kQocW4v0Ar5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1EmMgO2RUNa-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba3dfef7-1348-4289-8b5e-63b4a455342f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Participant Data'\n",
        "prep_data = {}\n",
        "\n",
        "\n",
        "for dir_ in os.listdir(path):\n",
        "    if not dir_.startswith('.'):\n",
        "        prep_data[dir_] = {}\n",
        "        for dir__ in os.listdir(os.path.join(path,dir_)):\n",
        "            if not dir__.startswith('.'):\n",
        "                prep_data[dir_][dir__] = {}\n",
        "                for dir___ in os.listdir(os.path.join(path,dir_,dir__)):\n",
        "                    prep_data[dir_][dir__][dir___] = []\n",
        "                    if not dir___.startswith('.'):\n",
        "                        if dir___ == 'keylogger_desktop':\n",
        "                            files = glob.glob(os.path.join(path,dir_,dir__,dir___) + '/*')\n",
        "                            for file in files:\n",
        "                                with open(file, 'r') as f:\n",
        "                                    lines = f.readlines()\n",
        "                                    for line in lines:\n",
        "                                        prep_data[dir_][dir__][dir___].append([x for x in line.split() if x != '-'])                            \n",
        "                            \n",
        "                        elif dir___ == 'keylogger_phone':\n",
        "                            files = glob.glob(os.path.join(path,dir_,dir__,dir___) + '/*')\n",
        "                            for file in files:\n",
        "                                with open(file, 'r') as f:\n",
        "                                    lines = f.readlines()\n",
        "                                    for line in lines:\n",
        "                                        prep_data[dir_][dir__][dir___]\n",
        "                                        prep_data[dir_][dir__][dir___].append([x.strip() for x in line.split(',')])                                        \n",
        "                            \n",
        "                        elif dir___ == 'mouselogger_desktop':\n",
        "                            files = glob.glob(os.path.join(path,dir_,dir__,dir___) + '/*')\n",
        "                            for file in files:\n",
        "                                with open(file, 'r') as f:\n",
        "                                    lines = f.readlines()\n",
        "                                    for line in lines:\n",
        "                                        prep_data[dir_][dir__][dir___].append([x for x in line.split()])\n",
        "\n",
        "\n",
        "                        elif dir___ == 'CA_output_phone':\n",
        "                            files = glob.glob(os.path.join(path,dir_,dir__,dir___) + '/*')\n",
        "                            for file in files:\n",
        "                                tokens = file.split('/')\n",
        "                                if 'ca_home_act_1.txt' not in tokens:\n",
        "                                    if 'ca_home_act_2.txt' in tokens:\n",
        "                                        with open(file, 'r') as f:\n",
        "                                            lines = f.readlines()\n",
        "                                            for i in range(0,len(lines),2):\n",
        "                                                prep_data[dir_][dir__][dir___].append([lines[i].strip(),lines[i+1].strip()])\n",
        "                                    elif 'ca_home_MainActivity.txt' in tokens:\n",
        "                                         with open(file, 'r') as f:\n",
        "                                             lines = f.readlines()\n",
        "                                             word = 'Pressure'\n",
        "                                             for line in lines:\n",
        "                                              if word in line:\n",
        "                                                continue\n",
        "                                              else:\n",
        "                                                prep_data[dir_][dir__][dir___].append([line.strip()])\n",
        "\n",
        "                        elif dir___ == 'CA_output_desktop':\n",
        "                              files = glob.glob(os.path.join(path,dir_,dir__,dir___) + '/*')\n",
        "                              for file in files:\n",
        "                                  if 'task_essay.docx' not in file.split('/'):\n",
        "                                    with open(file, 'rb') as f:\n",
        "                                          #source_stream = io.BytesIO(f.read())\n",
        "                                          document = docx.Document(file)\n",
        "                                          for line in document.paragraphs:\n",
        "                                              prep_data[dir_][dir__][dir___].append([line.text])\n",
        "\n",
        "                        elif dir___ == 'chat_output_phone':\n",
        "                            files = glob.glob(os.path.join(path,dir_,dir__,dir___) + '/*')\n",
        "                            for file in files:\n",
        "                                tokens = file.split('/')\n",
        "                                if 'chat_Communication.txt' in tokens:\n",
        "                                    with open(file, 'r') as f:\n",
        "                                        lines = f.readlines()\n",
        "                                        count = 0\n",
        "                                        for line in lines:\n",
        "                                            count +=1\n",
        "                                            if count % 2 == 1:\n",
        "                                              prep_data[dir_][dir__][dir___].append([line.split(',')])\n",
        "                                         \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MzFd-6Q3Pxdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the participant desired within the prep_data['P00XX']"
      ],
      "metadata": {
        "id": "iWKn-tbj-nGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prep_data['P0004']"
      ],
      "metadata": {
        "id": "wbAfbGIFlC3G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}